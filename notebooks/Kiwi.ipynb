{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import roboscientist.equation.equation as rs_equation\n",
    "from experiments import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.sort(np.sort(np.random.uniform(-5, 5, 25)))[..., None]\n",
    "noise = 1e-3 * np.random.rand(*X.shape)\n",
    "y = X ** 3 + X ** 2 + X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist/notebooks/../src/experiments.py:107: UserWarning: Logging disabled! Please provide wandb_key at /home/mikhail/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist\n",
      "  warnings.warn('Logging disabled! Please provide wandb_key at {}'.format(root_dir))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START PRETRAIN =====\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 17.599, rec loss: 17.537, kl: 0.123\n",
      "\t[validation] loss: 14.710, rec loss: 14.545, kl: 0.329\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 15.428, rec loss: 15.169, kl: 0.519\n",
      "\t[validation] loss: 14.278, rec loss: 13.901, kl: 0.753\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 15.124, rec loss: 14.665, kl: 0.917\n",
      "\t[validation] loss: 14.184, rec loss: 13.563, kl: 1.243\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.894, rec loss: 14.132, kl: 1.523\n",
      "\t[validation] loss: 13.795, rec loss: 12.896, kl: 1.796\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.594, rec loss: 13.498, kl: 2.191\n",
      "\t[validation] loss: 13.515, rec loss: 12.288, kl: 2.454\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.380, rec loss: 12.994, kl: 2.772\n",
      "\t[validation] loss: 13.360, rec loss: 11.966, kl: 2.788\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.251, rec loss: 12.701, kl: 3.101\n",
      "\t[validation] loss: 13.372, rec loss: 11.747, kl: 3.250\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.111, rec loss: 12.394, kl: 3.435\n",
      "\t[validation] loss: 13.194, rec loss: 11.524, kl: 3.341\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 14.005, rec loss: 12.114, kl: 3.782\n",
      "\t[validation] loss: 12.952, rec loss: 11.001, kl: 3.903\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.913, rec loss: 11.848, kl: 4.129\n",
      "\t[validation] loss: 12.798, rec loss: 10.780, kl: 4.035\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.827, rec loss: 11.651, kl: 4.352\n",
      "\t[validation] loss: 12.688, rec loss: 10.525, kl: 4.326\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.685, rec loss: 11.326, kl: 4.719\n",
      "\t[validation] loss: 12.556, rec loss: 10.206, kl: 4.700\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.608, rec loss: 11.091, kl: 5.033\n",
      "\t[validation] loss: 12.614, rec loss: 10.007, kl: 5.213\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.457, rec loss: 10.722, kl: 5.471\n",
      "\t[validation] loss: 12.389, rec loss: 9.674, kl: 5.429\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.337, rec loss: 10.405, kl: 5.863\n",
      "\t[validation] loss: 12.634, rec loss: 9.658, kl: 5.952\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.189, rec loss: 10.101, kl: 6.176\n",
      "\t[validation] loss: 11.995, rec loss: 8.945, kl: 6.100\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 13.120, rec loss: 9.862, kl: 6.516\n",
      "\t[validation] loss: 12.124, rec loss: 8.988, kl: 6.271\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.981, rec loss: 9.528, kl: 6.905\n",
      "\t[validation] loss: 12.019, rec loss: 8.658, kl: 6.721\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.865, rec loss: 9.263, kl: 7.205\n",
      "\t[validation] loss: 11.941, rec loss: 8.290, kl: 7.301\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.790, rec loss: 9.029, kl: 7.521\n",
      "\t[validation] loss: 11.779, rec loss: 8.189, kl: 7.180\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.679, rec loss: 8.826, kl: 7.705\n",
      "\t[validation] loss: 11.553, rec loss: 7.671, kl: 7.763\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.620, rec loss: 8.627, kl: 7.985\n",
      "\t[validation] loss: 11.380, rec loss: 7.412, kl: 7.936\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.445, rec loss: 8.318, kl: 8.253\n",
      "\t[validation] loss: 11.603, rec loss: 7.476, kl: 8.252\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.515, rec loss: 8.301, kl: 8.429\n",
      "\t[validation] loss: 11.338, rec loss: 7.284, kl: 8.108\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.409, rec loss: 8.130, kl: 8.557\n",
      "\t[validation] loss: 11.244, rec loss: 6.977, kl: 8.534\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.325, rec loss: 7.926, kl: 8.797\n",
      "\t[validation] loss: 11.300, rec loss: 7.028, kl: 8.544\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.210, rec loss: 7.696, kl: 9.028\n",
      "\t[validation] loss: 11.334, rec loss: 6.877, kl: 8.914\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.277, rec loss: 7.776, kl: 9.001\n",
      "\t[validation] loss: 11.016, rec loss: 6.553, kl: 8.926\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.065, rec loss: 7.383, kl: 9.364\n",
      "\t[validation] loss: 11.050, rec loss: 6.430, kl: 9.242\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.055, rec loss: 7.268, kl: 9.573\n",
      "\t[validation] loss: 11.016, rec loss: 6.331, kl: 9.370\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 12.000, rec loss: 7.158, kl: 9.684\n",
      "\t[validation] loss: 10.748, rec loss: 5.901, kl: 9.695\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.940, rec loss: 6.989, kl: 9.902\n",
      "\t[validation] loss: 10.803, rec loss: 5.965, kl: 9.677\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.841, rec loss: 6.816, kl: 10.050\n",
      "\t[validation] loss: 10.684, rec loss: 5.687, kl: 9.995\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.834, rec loss: 6.706, kl: 10.256\n",
      "\t[validation] loss: 11.019, rec loss: 6.004, kl: 10.029\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.695, rec loss: 6.484, kl: 10.422\n",
      "\t[validation] loss: 10.579, rec loss: 5.373, kl: 10.411\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.677, rec loss: 6.388, kl: 10.578\n",
      "\t[validation] loss: 10.702, rec loss: 5.460, kl: 10.484\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.717, rec loss: 6.383, kl: 10.669\n",
      "\t[validation] loss: 10.585, rec loss: 5.285, kl: 10.602\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.525, rec loss: 6.082, kl: 10.886\n",
      "\t[validation] loss: 10.355, rec loss: 4.923, kl: 10.864\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.755, rec loss: 6.364, kl: 10.783\n",
      "\t[validation] loss: 10.416, rec loss: 5.146, kl: 10.541\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.414, rec loss: 5.884, kl: 11.059\n",
      "\t[validation] loss: 10.327, rec loss: 4.867, kl: 10.920\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.432, rec loss: 5.823, kl: 11.219\n",
      "\t[validation] loss: 10.511, rec loss: 5.012, kl: 11.000\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.350, rec loss: 5.677, kl: 11.346\n",
      "\t[validation] loss: 10.450, rec loss: 4.876, kl: 11.148\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.390, rec loss: 5.685, kl: 11.411\n",
      "\t[validation] loss: 10.302, rec loss: 4.701, kl: 11.203\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.288, rec loss: 5.517, kl: 11.543\n",
      "\t[validation] loss: 10.352, rec loss: 4.770, kl: 11.165\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.279, rec loss: 5.489, kl: 11.580\n",
      "\t[validation] loss: 10.611, rec loss: 4.937, kl: 11.347\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.254, rec loss: 5.438, kl: 11.633\n",
      "\t[validation] loss: 10.220, rec loss: 4.445, kl: 11.552\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.197, rec loss: 5.341, kl: 11.712\n",
      "\t[validation] loss: 10.264, rec loss: 4.475, kl: 11.578\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.228, rec loss: 5.302, kl: 11.852\n",
      "\t[validation] loss: 10.120, rec loss: 4.386, kl: 11.469\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.170, rec loss: 5.227, kl: 11.886\n",
      "\t[validation] loss: 10.121, rec loss: 4.423, kl: 11.395\n",
      "\t[training] batches count: 157\n",
      "\t[training] loss: 11.116, rec loss: 5.149, kl: 11.935\n",
      "\t[validation] loss: 10.422, rec loss: 4.677, kl: 11.491\n",
      "===== END PRETRAIN =====\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 12.383, rec loss: 7.269, kl: 10.229\n",
      "\t[validation] loss: 11.069, rec loss: 5.528, kl: 11.081\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 11.628, rec loss: 6.175, kl: 10.906\n",
      "\t[validation] loss: 10.903, rec loss: 5.459, kl: 10.888\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 11.626, rec loss: 6.184, kl: 10.885\n",
      "\t[validation] loss: 10.058, rec loss: 4.425, kl: 11.265\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.991, rec loss: 5.348, kl: 11.285\n",
      "\t[validation] loss: 10.486, rec loss: 4.731, kl: 11.510\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.928, rec loss: 5.191, kl: 11.473\n",
      "\t[validation] loss: 10.191, rec loss: 4.561, kl: 11.260\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.781, rec loss: 5.187, kl: 11.188\n",
      "\t[validation] loss: 10.559, rec loss: 4.829, kl: 11.460\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 11.235, rec loss: 5.452, kl: 11.567\n",
      "\t[validation] loss: 10.776, rec loss: 5.163, kl: 11.227\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.921, rec loss: 5.393, kl: 11.056\n",
      "\t[validation] loss: 10.378, rec loss: 4.702, kl: 11.352\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.632, rec loss: 5.070, kl: 11.124\n",
      "\t[validation] loss: 10.444, rec loss: 4.888, kl: 11.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.532, rec loss: 5.065, kl: 10.935\n",
      "\t[validation] loss: 10.139, rec loss: 4.669, kl: 10.940\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.784, rec loss: 5.309, kl: 10.950\n",
      "\t[validation] loss: 10.404, rec loss: 4.932, kl: 10.944\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.368, rec loss: 4.932, kl: 10.874\n",
      "\t[validation] loss: 10.092, rec loss: 4.654, kl: 10.876\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.342, rec loss: 4.948, kl: 10.788\n",
      "\t[validation] loss: 10.219, rec loss: 4.757, kl: 10.924\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 10.108, rec loss: 4.678, kl: 10.859\n",
      "\t[validation] loss: 9.713, rec loss: 4.255, kl: 10.916\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.946, rec loss: 4.581, kl: 10.729\n",
      "\t[validation] loss: 9.615, rec loss: 4.344, kl: 10.543\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.678, rec loss: 4.500, kl: 10.357\n",
      "\t[validation] loss: 9.445, rec loss: 4.310, kl: 10.269\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.847, rec loss: 4.735, kl: 10.224\n",
      "\t[validation] loss: 9.713, rec loss: 4.560, kl: 10.305\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.773, rec loss: 4.641, kl: 10.265\n",
      "\t[validation] loss: 9.393, rec loss: 4.206, kl: 10.373\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.729, rec loss: 4.596, kl: 10.267\n",
      "\t[validation] loss: 9.141, rec loss: 3.973, kl: 10.335\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.671, rec loss: 4.438, kl: 10.466\n",
      "\t[validation] loss: 9.125, rec loss: 3.897, kl: 10.455\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.732, rec loss: 4.461, kl: 10.541\n",
      "\t[validation] loss: 9.196, rec loss: 3.950, kl: 10.491\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.482, rec loss: 4.282, kl: 10.400\n",
      "\t[validation] loss: 9.106, rec loss: 3.948, kl: 10.316\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.615, rec loss: 4.492, kl: 10.244\n",
      "\t[validation] loss: 9.173, rec loss: 4.092, kl: 10.162\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.759, rec loss: 4.647, kl: 10.225\n",
      "\t[validation] loss: 9.259, rec loss: 4.132, kl: 10.254\n",
      "\t[training] batches count: 1\n",
      "\t[training] loss: 9.250, rec loss: 4.189, kl: 10.122\n",
      "\t[validation] loss: 9.017, rec loss: 3.925, kl: 10.183\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'const_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31109/3024087616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist/notebooks/../src/experiments.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(X, y_true, true_formula, functions, free_variables, wandb_proj, project_name, constants, const_opt_method, float_constants, epochs, train_size, test_size, n_formulas_to_sample, max_formula_length, formula_predicate, device, latent, lstm_hidden_dim, log_intermediate_steps, pretrain_path)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexity_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpareto_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mcomplexity_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpareto_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_best_per_complexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist/notebooks/../src/experiments.py\u001b[0m in \u001b[0;36mfinal_log\u001b[0;34m(pareto_best_formulas)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mpareto_best_formulas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpareto_best_formulas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_optimize_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_formula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_opt_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_formula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist/notebooks/../src/roboscientist/solver/vae_solver_lib/optimize_constants.py\u001b[0m in \u001b[0;36moptimize_constants\u001b[0;34m(candidate_equation, X, y, method, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Optimization method {method} do not implemented\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Kiwi_project/Datasets/SEGVAE/RoboScientist/notebooks/../src/roboscientist/solver/vae_solver_lib/optimize_constants.py\u001b[0m in \u001b[0;36mbfgs_optimize\u001b[0;34m(candidate_equation, X, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbfgs_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcandidate_equation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'const_count'"
     ]
    }
   ],
   "source": [
    "solver = run_experiment(X, y, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmin(solver.stats.last_n_best_mses)\n",
    "equations = np.array(solver.stats.last_n_best_formulas)\n",
    "eq = rs_equation.Equation(equations[best_idx].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mikhail/anaconda3/envs/segvae/bin/jupyter\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw equation in prefix notation: ', equations[best_idx])\n",
    "print('Equation in traditional notation: ', eq.repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
